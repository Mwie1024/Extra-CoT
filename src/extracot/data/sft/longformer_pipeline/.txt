先用/metamath_145k_inference_result_original_question/filter_correct_answer.py筛选出正确答案，分别筛选出正确结果与qwen2.5-7b-instruct有交集和无交集的两部分，记为overlap.jsonl和no-overlap.jsonl

从overlap.jsonl中用metamath_145k_inference_result_original_question/select_sft_subset.py筛选出15k的子集留作指令跟随的备选项（按照"0,512,1024,2048,3072,4070"进行桶划分），通过longformer进行0.1-0.9的压缩，压缩完成后通过longformer_pipeline/filter_by_token_ratio.py进行实际压缩比的重新分配，最后通过longformer_pipeline/intersect_by_question.py构建出完整的压缩比跟随数据约60k，然后再通过longformer_pipeline/Compression/SFT_actual_ratio_intersection/replace_think_with_compressed_cot.py得到最终数据

同理对自适应跟随的数据集进行同理操作，不过先需要通过longformer_pipeline/Compression/RL_actual_ratio/sample_recat_10k_auto_data.py得到10k的难度挂钩的题目，再通过replace_think_with_compressed_cot.py得到最终自适应压缩比的数据集

合并二者得到最终sft数据

